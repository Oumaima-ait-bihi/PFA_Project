# Documentation : Tests de Performance avec JMeter

## ğŸ“‹ Vue d'ensemble

**JMeter** est un outil open-source utilisÃ© pour tester les performances des applications web. Dans ce projet, nous avons utilisÃ© JMeter pour tester les performances de l'API du systÃ¨me d'alerte clinique.

## ğŸ¯ Objectif des tests

L'objectif est de vÃ©rifier que l'API peut gÃ©rer plusieurs requÃªtes simultanÃ©es sans ralentir ou planter. Cela permet de s'assurer que le systÃ¨me fonctionnera correctement mÃªme avec plusieurs utilisateurs connectÃ©s en mÃªme temps.

## ğŸ“ Fichiers crÃ©Ã©s

### 1. Plan de test (`plan_test_alert_clinique.jmx`)
C'est le fichier principal qui contient tous les tests Ã  exÃ©cuter. Il dÃ©finit :
- **Quelles requÃªtes** tester (authentification, rÃ©cupÃ©ration de patients, prÃ©dictions IA, etc.)
- **Combien d'utilisateurs** simultanÃ©s simuler
- **Combien de fois** rÃ©pÃ©ter chaque test
- **Comment** mesurer les performances

### 2. Scripts d'exÃ©cution
- `LANCER_TEST_JMETER.bat` : Lance les tests en mode automatique (sans interface graphique)
- `LANCER_TEST_JMETER_GUI.bat` : Ouvre JMeter avec l'interface graphique pour voir les tests en temps rÃ©el

## ğŸ”§ Configuration des tests

### ParamÃ¨tres principaux

1. **Thread Group (Groupe de threads)**
   - **Nombre d'utilisateurs** : 10 utilisateurs simultanÃ©s
   - **Temps de montÃ©e** : 10 secondes (les utilisateurs se connectent progressivement)
   - **Nombre de boucles** : 1 fois par utilisateur

2. **RequÃªtes testÃ©es**
   - Authentification (login)
   - RÃ©cupÃ©ration de la liste des patients
   - RÃ©cupÃ©ration d'un patient par ID
   - CrÃ©ation d'un patient
   - RÃ©cupÃ©ration des alertes
   - PrÃ©diction IA
   - Et d'autres endpoints de l'API

3. **Listeners (Ã‰couteurs)**
   - **View Results Tree** : Affiche chaque requÃªte en dÃ©tail
   - **Summary Report** : Statistiques globales
   - **Aggregate Report** : Statistiques par endpoint

## ğŸ“Š RÃ©sultats des tests

### MÃ©triques mesurÃ©es

1. **Temps de rÃ©ponse** : Temps que prend l'API pour rÃ©pondre
   - Bon : < 200ms
   - Acceptable : 200-500ms
   - Lent : > 500ms

2. **Throughput** : Nombre de requÃªtes traitÃ©es par seconde
   - Plus c'est Ã©levÃ©, mieux c'est

3. **Taux d'erreur** : Pourcentage de requÃªtes qui Ã©chouent
   - IdÃ©al : 0%
   - Acceptable : < 1%

4. **Latence** : Temps entre l'envoi de la requÃªte et le dÃ©but de la rÃ©ponse

### OÃ¹ voir les rÃ©sultats

1. **Dans JMeter (interface graphique)**
   - Ouvrez les listeners en bas de l'arbre
   - Les rÃ©sultats s'affichent en temps rÃ©el pendant l'exÃ©cution

2. **Rapport HTML**
   - GÃ©nÃ©rÃ© automatiquement aprÃ¨s les tests
   - Emplacement : `jmeter/results/html-report_*/index.html`
   - Contient des graphiques et statistiques dÃ©taillÃ©es

3. **Fichier JTL**
   - Format CSV avec toutes les mÃ©triques
   - Emplacement : `jmeter/results/results_*.jtl`
   - Peut Ãªtre ouvert avec Excel pour analyse

## ğŸš€ Comment utiliser

### Option 1 : Mode automatique (recommandÃ©)

```bash
# Double-cliquez sur :
LANCER_TEST_JMETER.bat
```

Le script :
1. VÃ©rifie que JMeter est installÃ©
2. Lance les tests automatiquement
3. GÃ©nÃ¨re un rapport HTML
4. Ouvre le rapport dans le navigateur

### Option 2 : Mode interface graphique

```bash
# Double-cliquez sur :
LANCER_TEST_JMETER_GUI.bat
```

Puis dans JMeter :
1. Cliquez sur "Summary Report" ou "Aggregate Report"
2. Cliquez sur le bouton RUN (â–¶ï¸ vert)
3. Observez les rÃ©sultats en temps rÃ©el

## âš™ï¸ Configuration technique

### Ports utilisÃ©s
- **Backend Spring Boot** : `http://localhost:8082`
- **Service IA Python** : `http://localhost:5000`

### PrÃ©requis
- Backend Spring Boot doit Ãªtre dÃ©marrÃ©
- Service IA Python doit Ãªtre dÃ©marrÃ©
- JMeter doit Ãªtre installÃ©

## ğŸ“ˆ InterprÃ©tation des rÃ©sultats

### Exemple de rÃ©sultats normaux

```
Summary Report:
- Samples: 150 (nombre total de requÃªtes)
- Average: 150ms (temps de rÃ©ponse moyen)
- Min: 50ms (temps minimum)
- Max: 500ms (temps maximum)
- Error %: 0.00% (aucune erreur)
- Throughput: 15.0/sec (15 requÃªtes par seconde)
```

### Signification

- âœ… **Tous les tests passent** : Le systÃ¨me fonctionne correctement
- âœ… **Temps de rÃ©ponse < 500ms** : L'API est rapide
- âœ… **Taux d'erreur = 0%** : Aucun problÃ¨me dÃ©tectÃ©
- âš ï¸ **Temps de rÃ©ponse > 1000ms** : L'API est lente, optimisation nÃ©cessaire
- âŒ **Taux d'erreur > 5%** : ProblÃ¨me Ã  corriger

## ğŸ” ProblÃ¨mes rÃ©solus

### 1. Erreur "java.net.URISyntaxException"
**ProblÃ¨me** : Les URLs Ã©taient mal configurÃ©es dans JMeter
**Solution** : Ajout d'un "HTTP Request Defaults" avec le serveur et le port corrects

### 2. Erreur "Problem updating GUI"
**ProblÃ¨me** : Trop de donnÃ©es affichÃ©es en temps rÃ©el
**Solution** : DÃ©sactivation du "View Results Tree" par dÃ©faut, utilisation du mode non-GUI pour les tests de charge

### 3. Tests vides (0 threads)
**ProblÃ¨me** : Variables non rÃ©solues dans le Thread Group
**Solution** : Remplacement des variables par des valeurs directes

## ğŸ“ Conclusion

Les tests JMeter permettent de :
- âœ… VÃ©rifier que l'API supporte plusieurs utilisateurs simultanÃ©s
- âœ… Identifier les endpoints lents
- âœ… DÃ©tecter les erreurs potentielles
- âœ… Mesurer les performances du systÃ¨me

Ces tests sont essentiels pour garantir que le systÃ¨me fonctionnera correctement en production avec de vrais utilisateurs.

